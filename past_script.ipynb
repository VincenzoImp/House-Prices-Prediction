{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas -q\n",
    "!pip install numpy -q\n",
    "!pip install geopy -q\n",
    "!pip install matplotlib -q\n",
    "!pip install seaborn -q\n",
    "!pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from matplotlib import colors\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "poi_df = pd.read_csv('data/poi.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaN_analysis(df):\n",
    "    # analysis1: percentage of NaN values in columns\n",
    "    d = {'column': [], 'n_nan': [], 'percentage': []}\n",
    "    for col in df.columns:\n",
    "        n_nan = df[(df[col].isna()) | (df[col].isnull())].shape[0]\n",
    "        d['column'].append(col)\n",
    "        d['n_nan'].append(n_nan)\n",
    "        d['percentage'].append((n_nan*100)/df.shape[0])\n",
    "    analysis1 = pd.DataFrame(d).sort_values('percentage', ascending=False).reset_index(drop=True)\n",
    "    # analysis2: number of NaN values in each row grouped by number of NaN values\n",
    "    d = {'n_nan': [], 'n_rows': []}\n",
    "    for n_nan in range(1, df.shape[1]+1):\n",
    "        n_rows = df[df.isna().sum(axis=1) == n_nan].shape[0]\n",
    "        d['n_nan'].append(n_nan)\n",
    "        d['n_rows'].append(n_rows)\n",
    "    analysis2 = pd.DataFrame(d).sort_values('n_nan', ascending=False).reset_index(drop=True)\n",
    "    return analysis1, analysis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1, analysis2 = NaN_analysis(poi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add to our dataset the feature number of point of interest. By running the NaN analysis we notice that the only columns that we can use are lat and lon, the others are mainly composed by NaNs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of the new feature will be the mean of the distances between each house and its closest point of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df = poi_df[['lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_poi(lat, lon, poi_df, radius=0.001):\n",
    "    # radius = 0.03 -> 3km\n",
    "    # get all poi in a certain radius from the current lat and lon\n",
    "    series = poi_df[(poi_df['lat']-lat)**2 + (poi_df['lon']-lon)**2 <= radius**2]\n",
    "    # n_poi = np.nan if series.shape[0] == 0 else series.shape[0]\n",
    "    return series.shape[0] # n_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['n_poi'] = train_df.apply(lambda x: get_n_poi(x['latitude'], x['longitude'], poi_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['n_poi'].hist(bins=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fill NaNs\n",
    "\n",
    "- check which entries are incorrect for some features and then fix or drop the entries (correctness)\n",
    "- solve the NaN, for each case decide if we fix or drop (completeness)\n",
    "- finally we can obtein the clean dataset, with which we can start to work and analyse it in step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by making an anysis of the NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1, analysis2 = NaN_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id\n",
    "train_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_count_percentage(df, col):\n",
    "    tmp = df[col].to_frame().copy()\n",
    "    tmp.fillna('NaN', inplace=True)\n",
    "    tmp['count'] = 0\n",
    "    tmp = tmp.groupby(col).count().reset_index().sort_values('count', ascending=False).reset_index(drop=True)\n",
    "    tmp['percentage'] = (tmp['count']*100)/df.shape[0]\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that for the features balcony and garden the NaN are actually 'False'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_count_percentage(train_df, 'balcony')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_count_percentage(train_df, 'garden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['garden'] = train_df['garden'].fillna(False)\n",
    "train_df['balcony'] = train_df['balcony'].fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode garden, balcony and condition. In order to have for each feature only int or float as data, in this way we can plot graphs to better understand what to do with the NaN if drop or fix them. \n",
    "\\\n",
    "We have to point out that we encode condition with the assumption that also the test data will have the same labels as the train data for the feature condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['garden'] = train_df['garden'].apply(lambda x: 1 if x == True else 0)\n",
    "train_df['balcony'] = train_df['balcony'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_conditions = {}\n",
    "index = 0\n",
    "for value in train_df['conditions'].unique():\n",
    "    if value not in map_conditions:\n",
    "        map_conditions[value] = index\n",
    "        index += 1\n",
    "map_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['conditions'] = train_df['conditions'].apply(lambda x: map_conditions[x])\n",
    "train_df['conditions'] = train_df['conditions'].apply(lambda x: np.nan if x == map_conditions[np.nan] else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each column that has at keast a NaN as a data we plot the histogram distribution also in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_wnan = []\n",
    "for col in train_df.columns:\n",
    "    if train_df[train_df[col].isna()].shape[0] > 0:\n",
    "        columns_wnan.append(col)\n",
    "columns_wnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(df, feature, min_value=None, max_value=None, b=100):\n",
    "    df = df.dropna(subset=[feature]).reset_index(drop=True) #before plotting we remove the NaNs otherwise it will not be possible to plot the graphs \n",
    "    if min_value == None:\n",
    "        min_value = df[feature].min()\n",
    "    if max_value == None:\n",
    "        max_value = df[feature].max()\n",
    "    tmp = df[df[feature] >= min_value]\n",
    "    tmp = tmp[tmp[feature] <= max_value]\n",
    "    plt.hist(tmp.loc[:, feature], bins=b)\n",
    "    plt.title('histogram distribution of {} (min_value: {}, max_value: {}, bins: {})'.format(feature, min_value, max_value, b))\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('index')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.hist2d(pd.Series(np.array([i for i in range(tmp.loc[:, feature].shape[0])])), tmp.loc[:, feature], bins=b, norm = colors.LogNorm())\n",
    "    plt.title('2D histogram distribution of {} (min_value: {}, max_value: {}, bins: {})'.format(feature, min_value, max_value, b))\n",
    "    plt.ylabel('value')\n",
    "    plt.xlabel('index')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_wnan:\n",
    "    get_hist(train_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can observe that we have enough information to use the algorithm: imputation of missing values - KNN imputer for all the features which have at least a NaN. \n",
    "\\\n",
    "Moving our attention to the KNNImputer, it will fill the NaNs using the mean value from the 5 nearest neighbors of each NaN found in the training set for each feature considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer()\n",
    "train_df = pd.DataFrame(imputer.fit_transform(train_df), columns=train_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run again the NaN analysis to verify that there are no more NaNs in any feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1, analysis2 = NaN_analysis(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that some NaN have been filled , by the KNN Imputer, with values which do not respect reality, for example we have that an house has 0.8 as elevator (which is neither 0 = no elevator nor 1 = yes elevator). Actually this is not a problem for the model, these data are valid for the mathematical model we are building.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ratio'] = train_df.apply(lambda x: x['n_rooms']/max(1, x['n_bathrooms']), axis=1)\n",
    "train_df['m2_per_bathrooms'] = train_df.apply(lambda x: (x['surface']/max(1, x['n_rooms']*3 + x['n_bathrooms'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset analysis\n",
    "\n",
    "- plot the features\n",
    "- remove the outliers (only on the train set) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot again the histograms also in 2D as before for every feature, with the only difference that now we have assigned values to the NaNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    get_hist(train_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graphs we can observe that there are no outliers for the features: id, balcony, garden, conditions, latitude, longitude, n_rooms and elevator. \n",
    "\\\n",
    "We do a boxplot only for the features with the outliers, in order to then remove the outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(df, feature):\n",
    "    plt.boxplot(df.loc[:, feature])\n",
    "    plt.title('boxplot of {}'.format(feature))\n",
    "    plt.ylabel('value')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    boxplot(train_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('price', axis=1)\n",
    "y_train = train_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer()\n",
    "X_train = pd.DataFrame(normalizer.fit_transform(X_train), columns=train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMStrain_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    plt.scatter(train_df[col], train_df['price'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the outliers with the z score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = train_df.shape[0]\n",
    "z_scores = zscore(MMStrain_df)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 2).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMStrain_df = MMStrain_df[filtered_entries]\n",
    "new_shape = MMStrain_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original shape: {}'.format(original_shape))\n",
    "print('new shape: {}'.format(new_shape))\n",
    "print('percentage of rows removed: {}%'.format(((original_shape-new_shape)*100)/original_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in MMStrain_df.columns:\n",
    "    plt.scatter(MMStrain_df[col], MMStrain_df['price'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ricalcolo lo zscore sulla singola feature e seleziono il sottoinsieme di entry che hanno zscore < 5 (tmp_df)\n",
    "# quindi calcolo il minimo e il massimo di tmp_df sulla feature che sto considerando per poi \n",
    "# sostituire i valori di train_df che hanno zscore > 5, sulla feature che sto considerando, con il minimo o il massimo\n",
    "'''\n",
    "for col in train_df.columns:\n",
    "    z_scores = zscore(train_df[col])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 5)\n",
    "    tmp_df = train_df[col][filtered_entries]\n",
    "    lower, upper = tmp_df.min(), tmp_df.max()\n",
    "    train_df[col] = train_df[col].apply(lambda x: lower if x < lower else upper if x > upper else x)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in MMStrain_df.columns:\n",
    "    get_hist(MMStrain_df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in MMStrain_df.columns:\n",
    "    boxplot(MMStrain_df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature importance analysis\n",
    "\n",
    "- may drop features that are not relevant for our model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMStrain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the random forest regressor we will compute the features importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x, y\n",
    "x = MMStrain_df.drop('price', axis=1)\n",
    "y = MMStrain_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# compute feature_importances\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(x, y)\n",
    "sorted(rf.feature_importances_, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature_importances\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "plt.barh(x.columns[sorted_idx], rf.feature_importances_[sorted_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the elevator is th efeature with least importance, we could drop it, but given the fact we have only 17 features we are going to keep it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MMStrain_df.drop(['elevator', 'balcony', 'garden', 'proximity_to_center'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add Samples (Oversampling)\n",
    "\n",
    "- in the case of regression we do not need to undersampling\n",
    "- quindi facciamo oversampling aumentando i samples sinteticamente con funzioni apposite (SMOTE)\n",
    "- oppure tramite integrazione di nuovi samples non sintetici da internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training\n",
    "\n",
    "- creare tutti i regressor possibili e trainarli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "tuned_rf = {'bootstrap': False,\n",
    " 'max_depth': None,\n",
    " 'max_features': 'sqrt',\n",
    " 'n_estimators': 500}\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(**tuned_rf),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'MLPRegressor': MLPRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMStrain_df.reset_index(drop=True, inplace=True)\n",
    "x = MMStrain_df.drop('price', axis=1)\n",
    "y = MMStrain_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print('model: {}'.format(model_name))\n",
    "    model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "def evaluate_model(model, x, y):\n",
    "    MAE_scores = cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=5, n_jobs=-1)\n",
    "    MSE_scores = cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "    # plot\n",
    "    y_pred = cross_val_predict(model, x, y, cv=5, n_jobs=-1)\n",
    "    plt.scatter(y, y_pred, alpha=0.5)\n",
    "    plt.plot([0, max(y.max(), y_pred.max())], [0, max(y.max(), y_pred.max())], 'r--', lw=2)\n",
    "    plt.xlabel('True price')\n",
    "    plt.ylabel('Predicted price')\n",
    "    plt.title('{}'.format(model))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('MAE: {:.3f} ({:.3f})'.format(-MAE_scores.mean(), MAE_scores.std()))\n",
    "    print('MSE: {:.3f} ({:.3f})'.format(-MAE_scores.mean(), MAE_scores.std()))\n",
    "    return MAE_scores, MSE_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {model_name: {'MSE_mean': 0.0, 'MSE_std': 0.0, 'MAE_mean': 0.0, 'MAE_std': 0.0} for model_name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    MAE_scores, MSE_scores = evaluate_model(model, x, y)\n",
    "    performance[model_name]['MAE_mean'] = -MAE_scores.mean()\n",
    "    performance[model_name]['MAE_std'] = MAE_scores.std()\n",
    "    performance[model_name]['MSE_mean'] = -MSE_scores.mean()\n",
    "    performance[model_name]['MSE_std'] = MSE_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame.from_dict(performance, orient='index').sort_values(by='MSE_mean').reset_index().rename(columns={'index': 'model'})\n",
    "performance_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Prediction test_df \n",
    "- performiamo i modelli trainati sul test set e quindi otteniamo le prediction per kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df_preprocessing(test_df, map_conditions, imputer, scaler):\n",
    "    test_df['n_poi'] = test_df.apply(lambda x: get_n_poi(x['latitude'], x['longitude'], poi_df), axis=1)\n",
    "    test_df['garden'] = test_df['garden'].fillna(False)\n",
    "    test_df['balcony'] = test_df['balcony'].fillna(False)\n",
    "    test_df['garden'] = test_df['garden'].apply(lambda x: 1 if x == True else 0)\n",
    "    test_df['balcony'] = test_df['balcony'].apply(lambda x: 1 if x == True else 0)\n",
    "    test_df['conditions'] = test_df['conditions'].apply(lambda x: map_conditions[x])\n",
    "    test_df['conditions'] = test_df['conditions'].apply(lambda x: np.nan if x == map_conditions[np.nan] else x)\n",
    "    test_df['ratio'] = test_df.apply(lambda x: x['n_rooms']/max(1, x['n_bathrooms']), axis=1)\n",
    "    test_df['m2_per_bathrooms'] = test_df.apply(lambda x: (x['surface']/max(1, x['n_rooms']*3 + x['n_bathrooms'])), axis=1)\n",
    "    test_df = pd.DataFrame(imputer.fit_transform(test_df), columns=test_df.columns)\n",
    "    #test_df.drop(['elevator', 'balcony', 'garden', 'proximity_to_center'], axis=1, inplace=True)\n",
    "    test_df = pd.DataFrame(scaler.fit_transform(test_df), columns=test_df.columns)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df['id']\n",
    "test_df.drop('id', axis=1, inplace=True)\n",
    "test_df = test_df_preprocessing(test_df, map_conditions, imputer, scaler)\n",
    "test_df = pd.concat([test_id, test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, test_df, filename):\n",
    "    submission_df = test_df['id'].to_frame()\n",
    "    # get predictions and save them in submission_df as 'price' column (in the right format for the submission)\n",
    "    submission_df['price'] = model.predict(test_df.drop('id', axis=1))\n",
    "    submission_df['id'] = submission_df['id'].astype(int)\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    submission(model, test_df, 'submission_{}.csv'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tuning\n",
    "\n",
    "- troviamo la combinazione di iperparametri migliori per il modello migliore che abbiamo fino ad ora ottenuto\n",
    "- quindi accordiamo il modello migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning random forest regressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(x, y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = RandomForestRegressor(**grid_search.best_params_)\n",
    "tuned_model.fit(x, y)\n",
    "MAE_score, MSE_score = evaluate_model(tuned_model, x, y)\n",
    "print('MAE: {:.3f} ({:.3f} std)'.format(-MAE_score.mean(), MAE_score.std()))\n",
    "print('MSE: {:.3f} ({:.3f} std)'.format(-MSE_score.mean(), MSE_score.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission(tuned_model, test_df, 'submission_tuned_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(tuned_model, test_df, 'submission_tuned_model.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
