{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries and load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas -q\n",
    "!pip install numpy -q\n",
    "!pip install matplotlib -q\n",
    "!pip install seaborn -q\n",
    "!pip install scikit-learn -q\n",
    "!pip install scipy -q\n",
    "!pip install feature_engine -q\n",
    "#!pip install pgeocode -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import math\n",
    "import seaborn as sns\n",
    "#import pgeocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "poi_df = pd.read_csv('data/poi.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Point of Interest Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df = poi_df.filter(['lat', 'lon', 'tags.addr:postcode']).rename(columns={'tags.addr:postcode':'postcode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_postcode(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df['postcode'] = poi_df['postcode'].apply(fix_postcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='lon', y='lat', data=poi_df)\n",
    "plt.title('POI Scatterplot Longitude vs Latitude')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Train Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop id\n",
    "train_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Add Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_poi(lat, lon, poi_df, radius=0.001):\n",
    "    if math.isnan(lat) or math.isnan(lon):\n",
    "        return np.nan\n",
    "    # radius = 0.03 -> 3km\n",
    "    # get all poi in a certain radius from the current lat and lon\n",
    "    series = poi_df[(poi_df['lat']-lat)**2 + (poi_df['lon']-lon)**2 <= radius**2]\n",
    "    # n_poi = np.nan if series.shape[0] == 0 else series.shape[0]\n",
    "    return series.shape[0] # n_poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postcode(lat, lon, poi_df, radius=0.001):\n",
    "    if math.isnan(lat) or math.isnan(lon):\n",
    "        return np.nan\n",
    "    # radius = 0.03 -> 3km\n",
    "    # get all poi in a certain radius from the current lat and lon\n",
    "    series = poi_df[(poi_df['lat']-lat)**2 + (poi_df['lon']-lon)**2 <= radius**2]\n",
    "    # n_poi = np.nan if series.shape[0] == 0 else series.shape[0]\n",
    "    if series.shape[0] == 0:\n",
    "        return np.nan\n",
    "    if series['postcode'].mode().shape[0] == 0:\n",
    "        return np.nan\n",
    "    return series['postcode'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['n_poi'] = train_df.apply(lambda x: get_n_poi(x['latitude'], x['longitude'], poi_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['postcode'] = train_df.apply(lambda x: get_postcode(x['latitude'], x['longitude'], poi_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_ratio(x):\n",
    "    n_room = x['n_rooms']\n",
    "    n_bathroom = x['n_bathrooms']\n",
    "    if not math.isnan(n_room) and not math.isnan(n_bathroom):\n",
    "        return n_room/max(1, n_bathroom) \n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ratio'] = train_df.apply(lambda x: lambda_ratio(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_m2_per_bathrooms(x):\n",
    "    n_room = x['n_rooms']\n",
    "    n_bathroom = x['n_bathrooms']\n",
    "    m2 = x['surface']\n",
    "    if not math.isnan(n_bathroom) and not math.isnan(m2):\n",
    "        return m2/max(1, n_room*3 + n_bathroom)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['m2_per_bathrooms'] = train_df.apply(lambda x: lambda_m2_per_bathrooms(x), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['garden'] = train_df['garden'].fillna(False)\n",
    "train_df['balcony'] = train_df['balcony'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['garden'] = train_df['garden'].apply(lambda x: 1 if x == True else 0)\n",
    "train_df['balcony'] = train_df['balcony'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_conditions = {}\n",
    "index = 0\n",
    "for value in train_df['conditions'].unique():\n",
    "    if value not in map_conditions:\n",
    "        map_conditions[value] = index\n",
    "        index += 1\n",
    "map_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['conditions'] = train_df['conditions'].apply(lambda x: map_conditions[x])\n",
    "train_df['conditions'] = train_df['conditions'].apply(lambda x: np.nan if x == map_conditions[np.nan] else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop('price', axis=1)\n",
    "y_train = train_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(x_scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "y_scaler = StandardScaler()\n",
    "y_train = pd.DataFrame(y_scaler.fit_transform(y_train.values.reshape(-1, 1)), columns=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "x_imputer = KNNImputer()\n",
    "x_train = pd.DataFrame(x_imputer.fit_transform(x_train), columns=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "x_normalizer = Normalizer()\n",
    "x_train = pd.DataFrame(x_normalizer.fit_transform(x_train), columns=x_train.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([x_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_shape = train_df.shape[0]\n",
    "z_scores = zscore(train_df)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 5).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[filtered_entries]\n",
    "new_shape = train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original shape: {}'.format(original_shape))\n",
    "print('new shape: {}'.format(new_shape))\n",
    "print('percentage of rows removed: {}%'.format(((original_shape-new_shape)*100)/original_shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop('price', axis=1)\n",
    "y_train = train_df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# compute feature_importances\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "sorted(rf.feature_importances_, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature_importances\n",
    "sorted_idx = rf.feature_importances_.argsort()\n",
    "plt.barh(x_train.columns[sorted_idx], rf.feature_importances_[sorted_idx])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'MLPRegressor': MLPRegressor(),\n",
    "    'SVR': SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print('model: {}'.format(model_name))\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def evaluate_model(model, x, y, y_scaler, scoring='neg_mean_squared_error'):\n",
    "    scores = cross_val_score(model, x, y, cv=5, scoring=scoring)\n",
    "    print('scores: {}'.format(scores))\n",
    "    print('mean: {}'.format(-scores.mean()))\n",
    "    print('std: {}'.format(scores.std()))\n",
    "    # plot scatter plot of y_pred vs y_true\n",
    "    y_pred = y_scaler.inverse_transform(model.predict(x).reshape(-1, 1))\n",
    "    y = y_scaler.inverse_transform(y.values.reshape(-1, 1))\n",
    "    plt.scatter(y, y_pred)\n",
    "    plt.plot([0, max(y.max(), y_pred.max())], [0, max(y.max(), y_pred.max())], 'r--', lw=2)\n",
    "    plt.title('{}'.format(model))\n",
    "    plt.xlabel('y_true')\n",
    "    plt.ylabel('y_pred')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {model_name: {'MSE_mean': 0.0, 'MSE_std': 0.0} for model_name in models.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print('model: {}'.format(model_name))\n",
    "    MSE_scores = evaluate_model(model, x_train, y_train, y_scaler, scoring='neg_mean_squared_error')\n",
    "    performance[model_name]['MSE_mean'] = -MSE_scores.mean()\n",
    "    performance[model_name]['MSE_std'] = MSE_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame.from_dict(performance, orient='index').sort_values(by='MSE_mean').reset_index().rename(columns={'index': 'model'})\n",
    "performance_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_test_preprocessing(x_test, poi_df, map_conditions, x_scaler, x_imputer, x_normalizer):\n",
    "    x_test['n_poi'] = x_test.apply(lambda x: get_n_poi(x['latitude'], x['longitude'], poi_df), axis=1)\n",
    "    x_test['ratio'] = x_test.apply(lambda x: lambda_ratio(x), axis=1)\n",
    "    x_test['m2_per_bathrooms'] = x_test.apply(lambda x: lambda_m2_per_bathrooms(x), axis=1)\n",
    "    x_test['garden'] = x_test['garden'].fillna(False)\n",
    "    x_test['balcony'] = x_test['balcony'].fillna(False)\n",
    "    x_test['garden'] = x_test['garden'].apply(lambda x: 1 if x == True else 0)\n",
    "    x_test['balcony'] = x_test['balcony'].apply(lambda x: 1 if x == True else 0)\n",
    "    x_test['conditions'] = x_test['conditions'].apply(lambda x: map_conditions[x])\n",
    "    x_test['conditions'] = x_test['conditions'].apply(lambda x: np.nan if x == map_conditions[np.nan] else x)\n",
    "    x_test = pd.DataFrame(x_scaler.transform(x_test), columns=x_test.columns)\n",
    "    x_test = pd.DataFrame(x_imputer.transform(x_test), columns=x_test.columns)\n",
    "    x_test = pd.DataFrame(x_normalizer.transform(x_test), columns=x_test.columns)\n",
    "    return x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test_df['id']\n",
    "x_test = test_df.drop('id', axis=1)\n",
    "x_test = x_test_preprocessing(x_test, poi_df, map_conditions, x_scaler, x_imputer, x_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(model, filename, x_test, y_scaler):\n",
    "    y_pred = y_scaler.inverse_transform(model.predict(x_test).reshape(-1, 1))\n",
    "    y_pred = pd.DataFrame(y_pred, columns=['price'])\n",
    "    submission_df = pd.concat([test_id, y_pred], axis=1)\n",
    "    submission_df.to_csv(filename, index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    submission(model, 'submission/{}.csv'.format(model_name), x_test, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tuning\n",
    "\n",
    "- troviamo la combinazione di iperparametri migliori per il modello migliore che abbiamo fino ad ora ottenuto\n",
    "- quindi accordiamo il modello migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400, 600],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = RandomForestRegressor(**best_params)\n",
    "tuned_model.fit(x_train, y_train)\n",
    "MSE_score = evaluate_model(tuned_model, x_train, y_train, y_scaler, scoring='neg_mean_squared_error')\n",
    "print('MSE: {:.3f} ({:.3f} std)'.format(-MSE_score.mean(), MSE_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(tuned_model, 'submission/tuned_model.csv', x_test, y_scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
